---
title: "Case 2"
author: "Mel Schwan"
date: "8/8/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Case Study II: Using Data Science to Define Data Science
## Due Date: August 17, 2019

DDSAnalytics is an analytics company that specializes in talent management solutions for Fortune 100 companies. Talent management is defined as the iterative process of developing and retaining employees. It may include workforce planning, employee training programs, identifying high-potential employees and reducing/preventing voluntary employee turnover (attrition). To gain a competitive edge over its competition, DDSAnalytics is planning to leverage data science for talent management. The executive leadership has identified predicting employee turnover as its first application of data science for talent management. Before the business green lights the project, they have tasked your data science team to conduct an analysis of existing employee data. 

This is a youtube video presention to the Frito Layes company discussing the data and it's potential. https://youtu.be/RFpn13B5Xn0

### Deliverable
In using data science to define data science, we need to keep in mind reproducibility. To this end, your project markdown code should be committed and pushed to GitHub. The deliverable is a link to the GitHub repository where the markdown code resides. 

We will provide the predication of the attriction value for each employee in the “CaseStudy2CompSet No Attrition.csv” file. We are to sort the employee numbers and write to my “Case2PredictionsSchwan Attrition.csv”.
```{r Libraryv, echo=FALSE}
library(caret)
library(tidyverse)
library(ROCR)
library(pROC)
library(dplyr)
library(ggplot2)
library(tibble)
library(readxl)
library(tidyverse)
library(ggthemes)
library(gplots)
library(skimr)
library(plyr)
library(corrplot)
library(gridExtra)
library(magrittr)
library(MASS)
library(leaps)
```

#Load the supplied datasets and evaluate

```{r Casestudy2_data, echo=TRUE}

employee_df<-read.csv("./WA_Fn-UseC_-HR-Employee-Attrition.csv")
dim(employee_df)
car::some(employee_df)
#Make a copy of employee_df for Modeling
retention_set = employee_df
skim(retention_set)
#Change attrition to numeric

comp_set<-read_csv("./CaseStudy2CompSet No Attrition.csv")
comp_set_study<-read_csv("./CaseStudy2-data.csv")
comp_set_nosalary<-read_xlsx("./CaseStudy2CompSet No Salary.xlsx")
skim(comp_set)
skim(comp_set_study)
skim(comp_set_nosalary)
#Change Attrition to numeric
employee_df[, c(2)] <- sapply(employee_df[, c(2)], as.numeric)
#Look for any empty cells
sum(is.na(retention_set))
sum(is.na(comp_set))
sum(is.na(comp_set_study))
sum(is.na(comp_set_nosalary))
```

#Get information on simple data statistics

```{r analysis}
#Plot some data comparisons

plottable1=table(retention_set$Attrition,retention_set$Age)
plottable3=table(retention_set$Attrition,retention_set$YearsSinceLastPromotion)
plottable4=table(retention_set$Attrition,retention_set$JobInvolvement)
plottable5=table(retention_set$Attrition,retention_set$PercentSalaryHike)
plottable6=table(retention_set$Attrition,retention_set$PerformanceRating)
plottable7=table(retention_set$Attrition,retention_set$YearsInCurrentRole)
plottable8=table(retention_set$Attrition,retention_set$YearsAtCompany)


barplot(plottable1, main="Employees left vs Age", xlab="Age",col=c("Blue","Yellow"),legend=rownames(plottable1),beside = TRUE)
barplot(plottable3, main="Employees left vs Years Since Last Promotion", xlab="YearsSinceLastPromotion", col=c("Blue","Yellow"),beside = TRUE)
barplot(plottable4, main="Employees left vs Job Involvement", xlab="Job Involvement", col=c("Blue","Yellow"),legend=rownames(plottable1),beside = TRUE)
barplot(plottable5, main="Employees left vs salary hike", xlab="salary hike in %", col=c("Blue","Yellow"),legend=rownames(plottable1),beside = TRUE)
barplot(plottable6, main="Employees left vs Performance Rating", xlab="PerformanceRating",col=c("Blue","Yellow"),legend=rownames(plottable1),beside = TRUE)
barplot(plottable7, main="Employees left vs Years in current Role", xlab="Years In Current Role ", col=c("Blue","Yellow"),legend=rownames(plottable1),beside = TRUE)
barplot(plottable8, main="Employees left vs Num of Years at Company", xlab="Num of Years", col=c("Blue","Yellow"),legend=rownames(plottable1),beside = TRUE)




```

#Do correlations to analyze impact of independent variables

```{r correlation}

corrplot::corrplot.mixed(corr=cor(employee_df[,c(1,24:26,28:35 )],use="complete.obs"),upper="pie",tl.pos="lt")

#Fit all independent variables to find out which ones are significant
Model1 <-Attrition ~ Age+BusinessTravel+DailyRate+Department+DistanceFromHome+Education+EducationField+EnvironmentSatisfaction+Gender+JobLevel+JobRole+JobSatisfaction+MaritalStatus+MonthlyIncome+NumCompaniesWorked+OverTime+PercentSalaryHike+JobInvolvement+PerformanceRating+EnvironmentSatisfaction+TotalWorkingYears+TrainingTimesLastYear+WorkLifeBalance+YearsAtCompany+YearsInCurrentRole+YearsSinceLastPromotion+YearsWithCurrManager

fit1 <- lm(Model1, data = employee_df)
summary(fit1)
leap1 <- regsubsets(Model1, data = employee_df, nbest=1)
plot(leap1, scale="adjr2")
#Trim done the features to top variables with p value significant 
Model2 <-Attrition ~ JobLevel+JobRole+TotalWorkingYears
fit2 <- lm(Model2, data = employee_df)
summary(fit2)
leap1 <- regsubsets(Model1, data = employee_df, nbest=1)
plot(leap1, scale="adjr2")


```
#Model building and fitting
```{r model fitting}

control <- trainControl(method="cv", number=10)
metric <- "Accuracy"

#Trim down model to attributing features
varsToKeep <- c('MonthlyIncome','Attrition','JobRole','YearsSinceLastPromotion','YearsInCurrentRole', 'EmployeeNumber')
#Create taining and test datasets
DstTrainTest <- retention_set[,varsToKeep]
idxSplit <- createDataPartition(employee_df$Attrition, p = 0.75, list=FALSE)
DstTrainModel <- DstTrainTest[idxSplit,]
DstTestModel <- DstTrainTest[-idxSplit,]
#Take attrition out of the model
trainX <- DstTrainModel[,names(DstTrainModel) != "Attrition"]
preProcValues <- preProcess(x = trainX,method = c("center", "scale"))
preProcValues

# kNN
set.seed(7)
fit.knn <- train(Attrition ~ ., data=DstTrainModel, method="knn", 
                 metric=metric, trControl=control, preProcess = c("center","scale"), tuneLength = 5)

# logistic regression
set.seed(7)
fit.glm <- train(Attrition ~ ., data=DstTrainModel, method="glm", metric=metric, trControl=control)

```
#Model accuracy for attrition test
```{r model accuracy}

# summarize accuracy of models
results <- resamples(list(
  glm=fit.glm, 
  knn=fit.knn ))
#summary(results)

# compare accuracy of models
dotplot(results)

DstTestModelClean <- DstTestModel
DstTestModelClean$Attrition <- NA
predictedval <- predict(fit.knn, newdata=DstTestModelClean)
# summarize results with confusion matrix
cm <- confusionMatrix(predictedval, DstTestModel$Attrition)

print('KNN Model Accuracy')
print(cm$table)
print(cm$overall)
print(cm$byClass)
# calculate accuracy of the model
Accuracy<-round(cm$overall[1],2)
print(Accuracy)


DstTestModelClean <- DstTestModel
DstTestModelClean$Attrition <- NA
predictedval <- predict(fit.glm, newdata=DstTestModelClean)
# summarize results with confusion matrix
cm <- confusionMatrix(predictedval, DstTestModel$Attrition)
print('GLM Model Accuracy')
print(cm$table)
print(cm$overall)
print(cm$byClass)
# calculate accuracy of the model
Accuracy<-round(cm$overall[1],2)
print(Accuracy)


```
#Model testing against new test set

```{r model testing}
#Put Attrition column in test dataframes

comp_set$Attrition = factor(x=c('No', 'Yes'))


varsToKeep <- c('MonthlyIncome','Attrition','JobRole','YearsSinceLastPromotion','YearsInCurrentRole', 'EmployeeNumber')

DstTrainTest <- comp_set[,varsToKeep]



DstTestModelClean <- DstTrainTest
DstTestModelClean$Attrition <- NA
predictedval <- predict(fit.knn, newdata=DstTestModelClean)
comp_set$Attrition = predictedval

write.csv(comp_set, file = "Case2PedictionsSchwan Attrition.csv")





```


I will take the datafile “CaseStudy2CompSet No Salary.csv” which is a set of 300 observations predicted salaries (ordered by ID) in a csv file.  I will call the file “Case2PredictionsSchwan Salary.csv”.  



```{r Salary, echo=FALSE}
#Do correlation focusing on the monthly income
corrplot::corrplot.mixed(corr=cor(employee_df[,c(19, 1,24:25,27:35 )],use="complete.obs"),upper="pie",tl.pos="lt")

#Fit all independent variables to find out which ones are significant
Model1 <-MonthlyIncome ~ Age+BusinessTravel+DailyRate+Department+DistanceFromHome+Education+EducationField+EnvironmentSatisfaction+Gender+JobLevel+JobRole+JobSatisfaction+MaritalStatus+NumCompaniesWorked+OverTime+PercentSalaryHike+JobInvolvement+PerformanceRating+EnvironmentSatisfaction+TotalWorkingYears+TrainingTimesLastYear+WorkLifeBalance+YearsAtCompany+YearsInCurrentRole+YearsSinceLastPromotion+YearsWithCurrManager

fit1 <- lm(Model1, data = employee_df)
plot(leap1, scale="adjr2")
summary(fit1)

#Plot the significant independent variables
leap1 <- regsubsets(Model1, data = employee_df, nbest=1)
plot(leap1, scale="adjr2")

#Redue model with only significant variables
Model2 <-MonthlyIncome ~ JobLevel+JobRole+TotalWorkingYears
fit2 <- lm(Model2, data = employee_df)
summary(fit2)
AIC(fit2)
BIC(fit2)
leap1 <- regsubsets(Model2, data = employee_df, nbest=1)
plot(leap1, scale="adjr2")
summary(fit2)


# JobLevel JobRole TotalWorkingYears will be used for the model

control <- trainControl(method="cv", number=10)
metric <- "Accuracy"

#Trim down model to attributing features
varsToKeep <- c('MonthlyIncome','JobLevel', 'JobRole', 'TotalWorkingYears', 'EmployeeNumber')

DstTrainTest <- retention_set[,varsToKeep]
idxSplit <- createDataPartition(employee_df$MonthlyIncome, p = 0.75, list=FALSE)
DstTrainModel <- DstTrainTest[idxSplit,]
DstTestModel <- DstTrainTest[-idxSplit,]

trainX <- DstTrainModel[,names(DstTrainModel) != "MonthlyIncome"]
preProcValues <- preProcess(x = trainX,method = c("center", "scale"))
preProcValues


# kNN
set.seed(7)
fit.knn <- train(MonthlyIncome ~ ., data=DstTrainModel, method="knn", 
                  trControl=control, preProcess = c("center","scale"), tuneLength = 5)

# logistic regression
set.seed(7)

fit.glm <- train(MonthlyIncome ~ ., data=DstTrainModel, method="glm",  trControl=control)

```

#Model accuracy test
```{r model accuracy for salary}
# summarize accuracy of models
results <- resamples(list(
  glm=fit.glm, 
  knn=fit.knn ))
summary(results)

# compare accuracy of models
dotplot(results)
```
#Model testing against new test set

```{r model testing of salary precision}
#Salary predictions


varsToKeep <- c('JobLevel', 'JobRole', 'TotalWorkingYears', 'EmployeeNumber')

DstTrainTest <- comp_set_nosalary[,varsToKeep]



DstTestModelClean <- DstTrainTest
DstTestModelClean$MonthlyIncome <- NA
predictedval <- predict(fit.knn, newdata=DstTestModelClean)
comp_set_nosalary$MonthlyIncome = predictedval

write.csv(comp_set, file = "Case2PedictionsSchwan Salary.csv")






```
